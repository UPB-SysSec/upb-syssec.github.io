<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://upb-syssec.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://upb-syssec.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-04-24T09:20:22+00:00</updated><id>https://upb-syssec.github.io/feed.xml</id><title type="html">System Security Group</title><subtitle>The System Security Group at Paderborn University. </subtitle><entry><title type="html">Circumventing the GFW with TLS Record Fragmentation</title><link href="https://upb-syssec.github.io/blog/2023/record-fragmentation/" rel="alternate" type="text/html" title="Circumventing the GFW with TLS Record Fragmentation"/><published>2023-06-27T00:00:00+00:00</published><updated>2023-06-27T00:00:00+00:00</updated><id>https://upb-syssec.github.io/blog/2023/record-fragmentation</id><content type="html" xml:base="https://upb-syssec.github.io/blog/2023/record-fragmentation/"><![CDATA[ <style>.light-only{display:block}.dark-only{display:block}html[data-theme="dark"] .light-only,html:not([data-theme="dark"]) .dark-only{display:none}d-footnote-list img{height:1.5em}d-footnote img{height:2em}details.legend img{height:2em}details.legend{text-align:left}.l-screen img{max-width:100%;margin-left:auto;margin-right:auto}</style> <p>TCP fragmentation has long been known as a viable deep packet inspection (DPI) circumvention technique. However, censors are increasingly aware of this technique. We propose TLS record fragmentation as a new censorship circumvention technique on the TLS layer that functions analogously to TCP fragmentation. Using TLS record fragmentation, we successfully circumvented the DPI of the Great Firewall of China (GFW). We also found that over 90% of TLS servers support this new circumvention technique. To contextualize TLS record fragmentation for future work, we discuss its possibilities and limitations.</p> <blockquote> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0x1703030005436972637517030300056d76656e74170303
  0005696e67207417030300056865204746170303000157
</code></pre></div> </div> </blockquote> <hr/> <h2 id="introduction">Introduction</h2> <p>In this section, we provide background information on TLS censorship and fragmentation before showing the viability of TLS record fragmentation in later sections.</p> <h3 id="tls-censorship">TLS (Censorship)</h3> <p>The TLS protocol provides confidentiality, authenticity, and integrity to internet traffic in a client‑server setting <d-cite key="tls12,tls13"></d-cite>. While TLS can encrypt arbitrary application data, it is prominently used to encrypt HTTP connections. Google Chrome reports that Chrome serves around 93% of its connections over HTTPS (HTTP+TLS) <d-cite key="chrome_https"></d-cite>. The encryption of HTTP makes HTTPS connections resilient to censors’ analyses of fields such as the HTTP Host header. However, before TLS can transmit encrypted application data it performs a so-called handshake. This unencrypted handshake contains the Server Name Indication (SNI), which mirrors the content of the HTTP Host header. The handshake is depicted below.</p> <p><img src="/assets/img/2023/06/record-frag/handshake-light.svg" alt="A TLS 1.2 handshake with an HTTP GET request." width="70%" style="margin: 0 auto" class="light-only"/> <img src="/assets/img/2023/06/record-frag/handshake-dark.svg" alt="(Dark mode image - for description see light mode image)" width="70%" style="margin: 0 auto" class="dark-only"/></p> <div class="caption"> A TLS 1.2 handshake. Unencrypted messages are marked in blue while encrypted messages are marked in yellow. The SNI extension is visible in the unencrypted ClientHello message while the Host header of the HTTP GET request is encrypted. </div> <p>Censors around the globe utilize the SNI extension to facilitate the censorship of HTTPS connections <d-cite key="russia_sni_throttling,sni_china,sni_india,sni_south_korea"></d-cite>. As a countermeasure, the IETF has proposed ESNI and ECH <d-cite key="ietf-tls-esni-16"></d-cite>. Both encrypt the SNI extension in the ClientHello message. Unfortunately, the standard is still in the drafting phase, and its adoption is far from widespread <d-cite key="sni_china"></d-cite>. The only website for which we could find a valid <a href="https://dns.google/query?name=crypto.cloudflare.com&amp;rr_type=HTTPS&amp;ecs=">ECH configuration</a> is Cloudflare’s designated testing server. The slow adoption of ECH necessitates intermediate solutions for SNI censorship circumvention. One such solution is the fragmentation of TLS messages across multiple TCP fragments, known as TCP fragmentation.</p> <h3 id="tcp-fragmentation">TCP Fragmentation</h3> <p>TCP is a stream-based protocol over which users and applications can send data using abstract data streams. These data streams are translated by TCP into actual network packets called TCP segments. Each TCP segment can contain either complete application messages or only parts of it. The latter is called TCP fragmentation and is depicted below with an HTTP GET message.</p> <p><img src="/assets/img/2023/06/record-frag/tcp_frag-light.svg" alt="TCP fragmented HTTP GET request." width="80%" style="margin: 0 auto" class="light-only"/> <img src="/assets/img/2023/06/record-frag/tcp_frag-dark.svg" alt="(Dark mode image - for description see light mode image)" width="80%" style="margin: 0 auto" class="dark-only"/></p> <div class="caption"> The left side contains an unfragmented HTTP GET request. The same request is depicted in two TCP segments on the right side. Censors that want to extract the hostname of the website from the fragmented HTTP GET request have to concatenate both fragments. </div> <p>Interestingly, TCP fragmentation can be used in censorship circumvention as it aggravates the complexity of traffic analysis. In the above example, a censor has to concatenate both TCP fragments to correctly identify the destination of the GET request. This effectively forces the censor to maintain a state and allocate costly memory for every connection it analyzes. The costs of analyzing TCP fragmentation caused many censors to ignore it in the past <d-cite key="geneva,liberate,throttling_twitter,india_sni"></d-cite>. As it proved successful, TCP fragmentation was implemented in various censorship circumvention tools <d-cite key="goodbyedpi,zapret,powertunnel,greentunnel"></d-cite>. Recently, though, China’s censor has become more sophisticated and begun handling TCP fragmentation <d-cite key="geneva"></d-cite>.</p> <h3 id="tls-record-fragmentation">TLS Record Fragmentation</h3> <p>While TLS messages can be fragmented over multiple TCP segments, they can also be fragmented on the TLS layer alone. This is possible because the TLS layer consists of two different layers: the TLS message layer and the TLS record layer. On the TLS record layer, every TLS message is wrapped in a TLS record structure. Most importantly, a single TLS message can be split across multiple TLS records, resulting in TLS record fragmentation. This is depicted in the figure below.</p> <p><img src="/assets/img/2023/06/record-frag/record_frag-light.svg" alt="TLS Record fragmented ClientHello message." width="80%" style="margin: 0 auto" class="light-only"/> <img src="/assets/img/2023/06/record-frag/record_frag-dark.svg" alt="TLS Record fragmented ClientHello message." width="80%" style="margin: 0 auto" class="dark-only"/></p> <div class="caption"> The left side depicts a TLS ClientHello message in a complete TLS record and TCP segment. A TLS record fragmented ClientHello message is depicted on the right. Both TLS records are contained in the same TCP segment. A censor that wants to analyze the SNI extension of the fragmented TLS message has to concatenate both TLS records. </div> <p>In this example, the SNI extension is split across different TLS records. Similar to TCP fragmentation, this forces the censor to maintain a state and allocate memory for potential reassembly. To the best of our knowledge, TLS record fragmentation has been proposed for censorship circumvention only by <a href="https://security.stackexchange.com/questions/56338/identifying-ssl-traffic">Thomas Pornin since 2014</a>. We are not aware of any analyses or implementations of TLS record fragmentation as a censorship circumvention technique. In this blog post, we bridge this gulf and effectively rediscover TLS record fragmentation as a viable censorship circumvention technique.</p> <h2 id="contributions">Contributions</h2> <p>Our primary contribution is circumventing China’s censor—The Great Firewall of China (GFW)—with TLS record fragmentation. To infer the feasibility of TLS record fragmentation on the internet, we also measured its support by TLS servers.</p> <h3 id="proof-of-concept">Proof Of Concept</h3> <p>As mentioned, we circumvented the GFW with TLS record fragmentation. To this end, we implemented a <a href="https://github.com/UPB-SysSec/DPYProxy">DPYProxy</a>: a simple Python proxy that applies TLS record fragmentation to all handshake messages passing through it. Next to TLS record fragmentation, DPYProxy supports TCP fragmentation both standalone and in combination with TLS record fragmentation. The proxy runs locally and can be set as an HTTP(S) proxy in browsers like Firefox or Chrome. Any previous HTTP(S) proxy—needed for IP censorship circumvention—can be provided to DPYProxy, which routes traffic through it as well. The figure below visualizes both our setup and the behavior of the GFW.</p> <div class="l-screen"> <img src="/assets/img/2023/06/record-frag/setup-light.svg" class="light-only" alt="Setup and censor handling of two test vectors."/> <img src="/assets/img/2023/06/record-frag/setup-dark.svg" class="dark-only" alt="Setup and censor handling of two test vectors."/> </div> <div class="caption"> This figure depicts the setup of our scans for two test vectors. We can see that the GFW intercepts unfragmented TLS ClientHello messages. It ignores TLS record fragmented TLS ClientHello messages. We omitted HTTP CONNECT messages sent to DPYProxy and the HTTP Proxy for improved readability. </div> <p>We set up DPYProxy on a vantage point in China (AS4837) and let it connect to an HTTP proxy in the <a href="https://www.dfn.de/en/">DFN</a>. From there, we queried <a href="https://wikipedia.org/wiki/turtle">https://wikipedia.org/wiki/turtle</a> using curl<d-footnote><code>curl -Ls --proxy 127.0.0.1:4433 https://wikipedia.org/wiki/turtle</code></d-footnote> with different settings of our DPYProxy. Specifically, we ran DPYProxy with any combination of TCP and TLS record fragmentation enabled. When combining TCP and TLS record fragmentation, we fit one TLS record into exactly one TCP segment. In all tests, we fragmented the ClientHello message before and after the SNI extension. We refer to this as “Early Split” and “Late Split” in the table of results below.</p> <table width="50%" style="margin: 0 auto; text-align:center"> <thead> <tr class="header"> <th style="text-align: left;"><span>Fragmentation</span></th> <th style="text-align: center;"><span>Split</span></th> <th style="text-align: right;"><span>Circumvents Censor</span></th> </tr> </thead> <tbody> <tr> <th style="text-align: left;"><span>None</span></th> <th style="text-align: left;"><span>-</span></th> <th style="text-align: right;"><span>-</span></th> </tr> <tr> <td rowspan="2" style="text-align: left;">TCP</td> <th style="text-align: left;"><span>Early</span></th> <th style="text-align: right;"><span>Yes</span></th> </tr> <tr> <th style="text-align: left;"><span>Late</span></th> <th style="text-align: right;"><span>-</span></th> </tr> <tr> <td rowspan="2" style="text-align: left;">TLS</td> <th style="text-align: left;"><span>Early</span></th> <th style="text-align: right;"><span>Yes</span></th> </tr> <tr> <th style="text-align: left;"><span>Late</span></th> <th style="text-align: right;"><span>Yes</span></th> </tr> <tr> <td rowspan="2" style="text-align: left;">TLS+TCP</td> <th style="text-align: left;"><span>Early</span></th> <th style="text-align: right;"><span>Yes</span></th> </tr> <tr> <th style="text-align: left;"><span>Late</span></th> <th style="text-align: right;"><span>Yes</span></th> </tr> </tbody> </table> <p><br/></p> <p>Our results lead to a few interesting conclusions. First, we could verify that TCP fragmentation can still circumvent the GFW. Specifically, the GFW only censored our connection attempts when the SNI extension was present in the first TCP segment. Here, we encountered both the primary and secondary censors of the GFW detected by Bock et al. <d-cite key="censor_backup"></d-cite>. Both censors are circumventable reliably with TLS record fragmentation; it suffices to place any byte of the ClientHello message into a different TLS record. For that, multiple TLS records can be either contained in a single TCP segment or split across multiple TCP segments. Overall, we detect that the GFW handles TCP fragmentation partially but is overchallenged with any kind of TLS record fragmentation.</p> <h3 id="tls-server-support">TLS Server Support</h3> <p>To assess the usability of TLS record fragmentation, we also measured TLS servers’ support for it. To this end, we analyzed the domains of the <a href="https://tranco-list.eu/">Tranco Top 1M list</a> and all <code class="language-plaintext highlighter-rouge">https://</code> domains from the <a href="https://github.com/citizenlab/test-lists/blob/master/lists/global.csv">global list of censored domains by the CitizenLab</a>. We provide the per-server results of our analysis on <a href="https://github.com/UPB-SysSec/TlsRecordFragmentationResults">GitHub</a>. Below, we summarize our results.</p> <style>.footnote-ref{color:var(--global-theme-color)!important;border-bottom:0;text-decoration:none}.distill-fn-style li{color:var(--global-distill-app-color)!important;font-size:.8em;line-height:1.7em}.distill-fn-style a{color:var(--global-distill-app-color)!important;border-bottom:0;text-decoration:none}.distill-fn-style a:hover{color:var(--global-hover-color)!important;border-bottom:0;text-decoration:none}</style> <table width="70%" style="margin: 0 auto; text-align:center"> <thead> <tr class="header"> <th style="text-align: left;"><span>List</span></th> <th style="text-align: right;"><span>Scanned<br/>Domains</span><sup><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref">a</a></sup></th> <th style="text-align: right;"><span>Support TLS<br/>record fragmentation</span></th> </tr> </thead> <tbody> <tr> <th style="text-align: left;"><span>CitizenLab</span></th> <th style="text-align: right;"><span>1 135 </span></th> <th style="text-align: right;"><span>1 092 (96.21%)</span></th> </tr> <tr> <th style="text-align: left;"><span>Tranco Top 1M</span></th> <th style="text-align: right;"><span>830 357</span></th> <th style="text-align: right;"><span>766 909 (92.36%)</span></th> </tr> </tbody> </table> <p><br/></p> <ol class="distill-fn-style" type="a"> <li id="fn1">We excluded domains that are not resolvable, do not handshake TLS, or requested exclusion from our scans in a previous scan.<a href="#fnref1" class="footnote-backlink" role="doc-backlink">[↩︎]</a></li> </ol> <p>We found that slightly over 96% of domains from the CitizenLab list support TLS record fragmentation. In comparison, the domains from the Tranco Top 1M list support TLS record fragmentation with a slightly smaller share of over 92%. Interestingly, TLS record fragmentation enjoys widespread support across all ranks of the Tranco Top 1M list as can be seen below.</p> <p><img src="/assets/img/2023/06/record-frag/record_frag_by_tranco_rank.svg" alt="TLS server support for TLS record fragmentation by Tranco rank." width="70%" style="display: block; margin: 0 auto"/></p> <p>Overall, we determined that TLS record fragmentation is largely supported by TLS servers as of today. This holds for the top TLS servers on the internet as well as censored domains.</p> <h2 id="discussion">Discussion</h2> <p>The GFW is the most sophisticated censor in the world and often also the first censor to implement new protocol analyses. As even the GFW does not analyze TLS messages that are fragmented over multiple TLS records, we believe that TLS record fragmentation circumvents other censors as well. To ascertain the viability of TLS record fragmentation around the world, we endorse an analysis in other countries.</p> <h3 id="how-can-you-manipulate-the-tls-handshake-with-a-proxy">How Can You Manipulate the TLS Handshake with a Proxy?</h3> <p>One might think that it’s impossible to manipulate TLS traffic as a MitM/proxy server. Fundamentally, that is correct. The TLS protocol authenticates TLS handshake messages with the Finished message. However, TLS does not authenticate the encompassing TLS record headers. These are only authenticated for encrypted handshake messages and application data. As we only manipulated the TLS record headers of unencrypted handshake messages we did not break the TLS handshake in our analyses. Any manipulation of other parts of the handshake such as the SNI extension would indeed break authentication.</p> <p>As another nitty-gritty detail: The addition of implicit sequence numbers with the addition of additional records does not break the following authentication of data. Sequence numbers are reset before encryption starts.</p> <h3 id="how-long-will-tls-record-fragmentation-stay-viable">How Long Will TLS Record Fragmentation Stay Viable?</h3> <p>Currently, we are not sure why TLS record fragmentation works so well on the GFW. We suggest that the GFW is currently only able to hold state on the TCP layer but not in its DPI of the TLS layer. If that is the case, we conjecture the GFW and other censors to require some time until they can reassemble TLS records as well. We are even more positive about the viability of circumvention techniques that combine alterations on the TLS and TCP layer. For instance, one could fragment a TLS handshake message on the TLS and TCP layer, send these segments out-of-order, and inject TLS or TCP packets with a low TTL in between. In the end, we cannot definitely answer how long TLS record fragmentation will work on the GFW. We still conjecture it to be viable for a non-negligible amount of time, especially as a building block for more sophisticated circumvention techniques.</p> <h3 id="cant-the-gfw-block-tls-record-fragmentation-completely">Can’t the GFW Block TLS Record Fragmentation Completely?</h3> <p>Yes, and no. The GFW could completely block all fragmented TLS messages. Doing so risks blocking all connections that exhibit naturally occurring TLS record fragmentation. TLS record fragmentation can occur naturally when the size of a TLS message (2^24 bytes max) exceeds the maximum size of a TLS record (2^16 bytes). Additionally, the maximum size of TLS records can be lowered with TLS extensions <d-cite key="rfc6066,rfc8449"></d-cite>. To minimize the viability of a complete block of TLS record fragmentation, we encourage browser vendors and other TLS clients to incorporate fragmented TLS records in their connection attempts. This might also convince the remaining server owners to start supporting TLS record fragmentation, improving the interoperability of the TLS landscape as a whole.</p> <h3 id="i-want-to-add-tls-record-fragmentation-to-my-dpi-circumvention-tool-what-do-i-have-to-consider">I Want to Add TLS Record Fragmentation to my DPI Circumvention Tool. What Do I Have to Consider?</h3> <p>As an application layer protocol, the TLS layer can be manipulated without root privileges on the operating system. This makes it possible for TLS clients such as custom browsers to enforce TLS fragmentation from user space. As TLS record headers can be manipulated as a MitM, it is also possible to implement TLS record fragmentation into DPI-circumventing proxies. DPYProxy does exactly that. Limitations exist for tools such as <a href="https://github.com/ValdikSS/GoodbyeDPI">GoodByeDpi</a> that manipulate TCP packets. For each newly added record, five bytes are inserted into the TCP stream. This leads to a mismatch in TCP sequence numbers between the client and server application. While the TCP sequence numbers can be changed accordingly this has to be done for all subsequent messages in the handshake. Ironically, this forces the circumvention tool to maintain a TCP connection state.</p> <h1 id="conclusion">Conclusion</h1> <p>In this blog post, we extended fragmentation-based censorship circumvention to the TLS layer. We hope to aid both researchers and people affected by censorship with an additional tool in the ongoing struggle against internet censorship. The code of our TLS record fragmentation proxy is accessible on <a href="https://github.com/UPB-SysSec/DPYProxy">GitHub</a>. Feel free to get in touch for discussions and follow-up work at <a href="mailto:niklas.niere@upb.de">niklas.niere@upb.de</a>.</p>]]></content><author><name>Niklas Niere</name></author><summary type="html"><![CDATA[How Fragmentation Can Be Extended to the TLS Layer]]></summary></entry><entry><title type="html">We Really Need to Talk About Session Tickets</title><link href="https://upb-syssec.github.io/blog/2023/session-tickets/" rel="alternate" type="text/html" title="We Really Need to Talk About Session Tickets"/><published>2023-04-19T00:00:00+00:00</published><updated>2023-04-19T00:00:00+00:00</updated><id>https://upb-syssec.github.io/blog/2023/session-tickets</id><content type="html" xml:base="https://upb-syssec.github.io/blog/2023/session-tickets/"><![CDATA[ <style>html[data-theme="dark"] .light-only,html:not([data-theme="dark"]) .dark-only{display:none}d-footnote-list img{height:1.5em}d-footnote img{height:2em}details.legend img{height:2em}details.legend{text-align:left}</style> <p>We recently published the paper “<a href="https://www.usenix.org/conference/usenixsecurity23/presentation/hebrok">We Really Need to Talk About Session Tickets: A Large-Scale Analysis of Cryptographic Dangers with TLS Session Tickets</a>“ <d-cite key="sessiontickets2023"></d-cite>. In this paper, we analyze the security of TLS session ticket implementations and deployed servers. Many servers used guessable keys to encrypt session tickets, allowing attackers to decrypt TLS traffic or to impersonate the server. We’ll present this in person at <a href="https://www.ruhrsec.de/2023/">RuhrSec in May</a> and at <a href="https://www.usenix.org/conference/usenixsecurity23">USENIX in August</a>. In this post, we give a brief overview of the paper and our results.</p> <hr/> <h2 id="what-are-session-tickets">What are Session Tickets?</h2> <p><img src="/assets/img/2023/04/session-tickets/handshake.drawio.svg" alt="Absract representation of a TLS 1.2 handshake and session resumption." width="100%" class="light-only"/> <img src="/assets/img/2023/04/session-tickets/handshake.dark.svg" alt="(Dark mode image - for description see light mode image)" width="100%" class="dark-only"/></p> <div class="caption"> (Left) A TLS 1.2<d-footnote>TLS 1.0 and TLS 1.1 behave the same way. For simplicity, we write TLS 1.2.</d-footnote> handshake with a DH key exchange. Here the server issues a ticket containing key material for the second handshake. (Right) A TLS 1.2 handshake using a ticket to resume the session. It does not perform another key exchange or authentication. <details class="legend"> <summary> Explanation of icons </summary> <table> <tr> <th>Icon</th> <th>Description</th> </tr> <tr> <td><img alt="user (Tessa) using behind a laptop" src="/assets/img/2023/04/session-tickets/ke-assets/tessa.png"/></td> <td>User who is connecting to the server</td> </tr> <tr> <td><img alt="server rack" src="/assets/img/2023/04/session-tickets/ke-assets/server.svg"/></td> <td>Server the user is connecting to</td> </tr> <tr> <td><img alt="speech bubble containing CH" src="/assets/img/2023/04/session-tickets/ke-assets/ch.drawio.svg"/></td> <td>Client Hello. A message containing a list of supported parameters.</td> </tr> <tr> <td><img alt="speech bubble containing SH" src="/assets/img/2023/04/session-tickets/ke-assets/sh.drawio.svg"/></td> <td>Server Hello. A message containing the chosen parameters.</td> </tr> <tr> <td><img alt="document with a wax seal" src="/assets/img/2023/04/session-tickets/ke-assets/certificate.svg"/></td> <td> Certificate sent by the server. The client has to verify it (including contained signatures).</td> </tr> <tr> <td><img alt="left half of a key" src="/assets/img/2023/04/session-tickets/ke-assets/ke-1.svg"/></td> <td> Key Exchange sent by the server. This is signed and has to be verified by the client.</td> </tr> <tr> <td><img alt="right half of a key" src="/assets/img/2023/04/session-tickets/ke-assets/ke-2.svg"/></td> <td> Key Exchange sent by the client.</td> </tr> <tr> <td><img alt="complete key" src="/assets/img/2023/04/session-tickets/ke-assets/key.svg"/></td> <td> The symmetric key derived from the key exchange.</td> </tr> <tr> <td><img alt="database" src="/assets/img/2023/04/session-tickets/ke-assets/db.svg"/></td> <td> Local storage of the client.</td> </tr> <tr> <td><img alt="blue key" src="/assets/img/2023/04/session-tickets/ke-assets/stek.drawio.svg"/></td> <td> Session Ticket Encryption Key (STEK). Used to encrypt the ticket. This should only be known to the server.</td> </tr> <tr> <td><img alt="entrance ticket" src="/assets/img/2023/04/session-tickets/ke-assets/ticket.svg"/></td> <td> The ticket containing key material for resumption.</td> </tr> </table> </details> </div> <p>Session tickets (RFC 5077 <d-cite key="rfc5077"></d-cite>) improve the performance of the TLS protocol. In a normal TLS handshake, the client and server have to agree on a shared secret key.<d-footnote>Depicted in the figure above as <img alt="left half of a key" src="/assets/img/2023/04/session-tickets/ke-assets/ke-1.svg"/> and <img alt="right half of a key" src="/assets/img/2023/04/session-tickets/ke-assets/ke-2.svg"/>.</d-footnote> Further, the server has to authenticate itself to the client using a certificate. The certificate contains a signature the client has to verify.<d-footnote> <img alt="A document with a wax-seal on it" src="/assets/img/2023/04/session-tickets/ke-assets/certificate.svg"/> Actually, the server sends a chain of certificates. Each certificate contains a signature of the parent certificate. Each signature has to be checked.<br/> The server also includes a signature over its key exchange <img alt="Right part of a key" src="/assets/img/2023/04/session-tickets/ke-assets/ke-1.svg"/> which the server has to compute, and the client has to verify. </d-footnote> Both of these are computationally expensive. To skip these steps in future connections, the server can send a ticket to the client. The ticket contains the established secret<d-footnote>The actual key material is not directly included. The master secret (1.2) or resumption secret/PSK (1.3). Additionally, some information about the connection parameters is included.</d-footnote> which is used in the next handshake. This allows the key exchange and certificate to be skipped. The client stores the ticket and established secret for the next handshake.</p> <p>Upon resumption, the client sends the ticket to the server, which can retrieve the secret from the ticket and resume the connection. As the client sends the ticket in plain upon resumption, the secret is encrypted with a key only known to the server. This key is called a Session Ticket Encryption Key (STEK). This way only the server is able to read the secret from the ticket.</p> <h3 id="issues-with-session-tickets">Issues with Session Tickets</h3> <p>While TLS session tickets bring significant performance improvements for TLS connections <d-cite key="BlogCloudflareSessionResumption"></d-cite>, they have become a major target of criticism raised by security experts <d-cite key="ValsordaBlogPost, TlsShortCuts, sy2018tracking"></d-cite>; if an attacker can extract the state from a ticket, they can impersonate the server or decrypt recorded TLS connections.<d-footnote>This holds for all versions of TLS. TLS 1.3 improved this by allowing to perform an additional key exchange. This prevents the passive decryption of data transmitted after the key exchange. It is still possible to decrypt the 0RTT data (sent before key exchange) or impersonate the server.</d-footnote></p> <p>Such dangers are not only theoretical; in 2020, Fiona Klute discovered a vulnerability affecting the security of the session resumption mechanism in GnuTLS <d-cite key="GnuTLSBugBlog,GnuTLSBug"></d-cite>. The server used an all-zero STEK in the initial key rotation interval, allowing an attacker to decrypt the session tickets and learn the included secret TLS state.</p> <p>Even if a client does not resume the ticket, their initial connection is still endangered by the ticket issuance. In TLS 1.2 a resumed session uses the same key material as the initial connection.<d-footnote>The actual cryptographic keys differ, however they are derived from the same master secret and other publicly observable fields.</d-footnote> This means, that an attacker able to extract the state from the ticket can also decrypt the initial connection. As the ticket is issued in plain, it is observable by an attacker.</p> <h2 id="scanning-the-web">Scanning the Web</h2> <p>We analyzed 12 open-source implementations to see how session tickets are usually formatted and which cryptographic algorithms are used to protect them. Using this knowledge, we implemented tests for five implementation pitfalls and vulnerabilities with TLS-Scanner<d-footnote><a href="https://github.com/tls-attacker/TLS-Scanner">TLS-Scanner (on GitHub)</a> is an open-source tool to evaluate TLS implementations.</d-footnote>. In this post, we focus on the tests of weak STEKs and reused keystreams. We scanned hosts from the Tranco List <d-cite key="LePochat2019"></d-cite> as well as randomly chosen IPv4 hosts with port 443 open. We performed three sets of scans:</p> <ol> <li> <p><strong>pre‑T1M</strong> and <strong>T1M</strong>: Our first scan of the Tranco top 1M was performed in May 2021 during the master thesis of Simon Nachtigall<d-cite key="nachtigallEvaluationTLSSession2021"></d-cite>. We only scanned for keys consisting exclusively of zero bytes in TLS 1.2 and 1.3. <br/> Before performing the final T1M scan, we performed several test scans, summarized as the <strong>pre‑T1M</strong> scan.</p> </li> <li> <p><strong>T100k</strong> and <strong>IP100k</strong> We performed two smaller but more detailed scans of 100k hosts each in April 2022. These were chosen as the top 100k from the Tranco list and 100k random IPv4 hosts that responded on port 443. For these, we also performed further tests not covered in this post.</p> </li> <li> <p><strong>IPF</strong> Last, we scanned the entire IPv4 address range in August 2022. To this end, we only collected session tickets and performed the tests afterward without having to contact the servers again. We performed three TLS connections per host using ZGrab2, each time attempting to obtain a session ticket. We chose this number as it reduces the number of connections while hopefully still managing to connect to different servers if there is a load balancer.</p> </li> </ol> <h3 id="first-findings">First Findings</h3> <table> <thead> <tr class="header"> <th style="text-align: left;"></th> <th style="text-align: right;"></th> <th style="text-align: center;"></th> <th colspan="2" style="text-align: center;"><strong>Encryption</strong></th> <th style="text-align: center;"></th> <th colspan="2" style="text-align: center;"><strong>Authentication</strong></th> <th style="text-align: center;"></th> <th style="text-align: center;"></th> </tr> </thead> <tbody> <tr> <th style="text-align: left;"><span>Scan</span></th> <th style="text-align: right;">Servers<br/>Found</th> <th style="text-align: center;"></th> <th style="text-align: right;">Algorithm</th> <th style="text-align: center;">Key</th> <th style="text-align: center;"></th> <th style="text-align: center;">Algorithm</th> <th style="text-align: center;">Key</th> <th style="text-align: center;"></th> <th style="text-align: center;"></th> </tr> <tr> <td rowspan="2" style="text-align: left;">pre-T1M</td> <td style="text-align: right;">1903</td> <td style="text-align: center;"></td> <td style="text-align: right;">AES-256-CBC</td> <td style="text-align: left;"><code>00 00 ... 00 00</code></td> <td style="text-align: center;"></td> <td colspan="2" style="text-align: center;">&ndash;</td> <td style="text-align: center;"></td> <td style="text-align: center;"></td> </tr> <tr> <td style="text-align: right;">20</td> <td style="text-align: center;"></td> <td style="text-align: right;">AES-128-CBC</td> <td style="text-align: left;"><code>00 00 ... 00 00</code></td> <td style="text-align: center;"></td> <td style="text-align: center;">HMAC-SHA256</td> <td style="text-align: left;"><code>00 00 ... 00 00</code></td> <td style="text-align: center;"></td> <td style="text-align: center;"></td> </tr> </tbody> </table> <p>Unexpectedly, the pre-T1M scan directly uncovered many servers using an all-zero STEK. In the pre-T1M scan, we scanned the Tranco top 100k hosts multiple times. Summed up over all scans, we found 1923 (<strong>1.9%</strong>) distinct servers using an all-zero STEK. These belonged to AWS and Stackpath.</p> <h4 id="aws">AWS</h4> <p>1,903 of the servers using an all-zero STEK were identified as belonging to AWS. These used AES-256-CBC to encrypt the tickets. We did not find the HMAC key and assume it was set correctly. Due to the high impact, we decided to report our finding before continuing with the full scan. The issue was promptly resolved<d-cite key="amazon_aws_issue"></d-cite>.</p> <p>We could see that the hosts were not vulnerable at all times but only in some time intervals. This suggested an error in the key rotation, which was later confirmed to us by AWS developers.</p> <h4 id="stackpath">Stackpath</h4> <p>We also found 20 hosts belonging to Stackpath that used an all-zero STEK and HMAC key. These tickets were encrypted using AES-128-CBC and authenticated using HMAC-SHA256. Again, we immediately reported the issue.</p> <p>The affected servers behaved differently from the AWS servers. When connecting to the server multiple times, only some tickets were encrypted using a weak STEK. This was not limited to a specific timeframe as in the case of AWS. Interestingly, we found all servers were hosted on the same IP address. Using an online reverse DNS lookup tool, we found a total of 171 domains on the same IP.<d-footnote>We used <a href="https://www.yougetsignal.com/tools/web-sites-on-web-server/">https://www.yougetsignal.com/tools/web-sites-on-web-server/</a>.</d-footnote> By scanning these, and collecting 1,000 tickets per hostname, we found a total of 90 hostnames for which we could observe vulnerable tickets. We identified that on vulnerable hosts, on average 1.4% of the issued tickets per host were affected. Stackpath did not give us any insight into how this came to be but resolved the issue.</p> <h3 id="further-weak-steks">Further Weak STEKs</h3> <style>.footnote-ref{color:var(--global-theme-color)!important;border-bottom:0;text-decoration:none}.distill-fn-style li{color:var(--global-distill-app-color)!important;font-size:.8em;line-height:1.7em}.distill-fn-style a{color:var(--global-distill-app-color)!important;border-bottom:0;text-decoration:none}.distill-fn-style a:hover{color:var(--global-hover-color)!important;border-bottom:0;text-decoration:none}</style> <div class="threeparttable l-page" style="margin: auto"> <table> <thead> <tr class="header"> <th style="text-align: left;"></th> <th style="text-align: right;"></th> <th style="text-align: center;"></th> <th colspan="2" style="text-align: center;"><strong>Encryption</strong></th> <th style="text-align: center;"></th> <th colspan="2" style="text-align: center;"><strong>Authentication</strong></th> <th style="text-align: center;"></th> <th style="text-align: center;"></th> </tr> </thead> <tbody> <tr> <th style="text-align: left;"><span>Scan</span></th> <th style="text-align: right;">Servers<br/>Found</th> <th style="text-align: center;"></th> <th style="text-align: right;">Algorithm</th> <th style="text-align: center;">Key</th> <th style="text-align: center;"></th> <th style="text-align: center;">Algorithm</th> <th style="text-align: center;">Key</th> <th style="text-align: center;"></th> <th style="text-align: center;"></th> </tr> <tr> <td style="text-align: left;">T1M</td> <td style="text-align: right;">3</td> <td style="text-align: center;"></td> <td style="text-align: right;">AES-128-CBC</td> <td style="text-align: left;"><code>00 00 ... 00 00</code></td> <td style="text-align: center;"></td> <td style="text-align: center;">HMAC-SHA256</td> <td style="text-align: left;"><code>00 00 ... 00 00</code></td> <td style="text-align: center;"></td> <td style="text-align: center;"></td> </tr> <tr> <td style="text-align: left;">IP100k</td> <td style="text-align: right;">0</td> <td style="text-align: center;"></td> <td colspan="2" style="text-align: center;">&ndash;</td> <td style="text-align: center;"></td> <td colspan="2" style="text-align: center;">&ndash;</td> <td style="text-align: center;"></td> <td style="text-align: center;"></td> </tr> <tr> <td style="text-align: left;">T100k</td> <td style="text-align: right;">1</td> <td style="text-align: center;"></td> <td style="text-align: right;">AES-128-CBC</td> <td style="text-align: left;"><code>00 00 ... 00 00</code></td> <td style="text-align: center;"></td> <td style="text-align: center;">HMAC-SHA256</td> <td style="text-align: left;"><code>00 00 ... 00 00</code></td> <td style="text-align: center;"></td> <td style="text-align: center;"></td> </tr> <tr> <td rowspan="5" style="text-align: left;">IPF</td> <td style="text-align: right;">5</td> <td style="text-align: center;"></td> <td style="text-align: right;">AES-256-CBC</td> <td style="text-align: left;"><code>00 00 ... 00 00</code></td> <td style="text-align: center;"></td> <td colspan="2" style="text-align: center;">&ndash;</td> <td style="text-align: center;"></td> <td style="text-align: center;"></td> </tr> <tr> <td style="text-align: right;">94</td> <td style="text-align: center;"></td> <td style="text-align: right;">AES-128-CBC</td> <td style="text-align: left;"><code>00 00 ... 00 00</code></td> <td style="text-align: center;"></td> <td style="text-align: center;">HMAC-SHA256</td> <td style="text-align: left;"><code>00 00 ... 00 00</code></td> <td style="text-align: center;"></td> <td style="text-align: center;"></td> </tr> <tr> <td style="text-align: right;">12</td> <td style="text-align: center;"></td> <td style="text-align: right;">AES-256-CBC</td> <td style="text-align: left;"><code>00 00 ... 00 00</code></td> <td style="text-align: center;"></td> <td style="text-align: center;">HMAC-SHA384</td> <td style="text-align: left;"><code>00 00 ... 00 00</code></td> <td style="text-align: center;"></td> <td style="text-align: center;"></td> </tr> <tr> <td style="text-align: right;">3</td> <td style="text-align: center;"></td> <td style="text-align: right;">AES-128-CBC</td> <td style="text-align: left;"><code>10 11 ... 1e 1f</code></td> <td style="text-align: center;"></td> <td style="text-align: center;">HMAC-SHA256</td> <td style="text-align: left;"><code>20...2f 00...00</code><sup><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref">a</a></sup></td> <td style="text-align: center;"></td> <td style="text-align: center;"></td> </tr> <tr> <td style="text-align: right;">75</td> <td style="text-align: center;"></td> <td style="text-align: right;">AES-256-CBC</td> <td style="text-align: left;"><code>31...31 00...00</code><sup><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref">b</a></sup></td> <td style="text-align: center;"></td> <td style="text-align: center;">HMAC-SHA256</td> <td style="text-align: left;"><code>31...31 00...00</code><sup><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref">b</a></sup></td> <td style="text-align: center;"></td> <td style="text-align: center;"></td> </tr> </tbody> </table> <ol class="distill-fn-style" type="a"> <li id="fn1">This key consists of 16 consecutively increasing bytes followed by 16 <code>0x00</code> bytes. <a href="#fnref1" class="footnote-backlink" role="doc-backlink">[↩︎]</a></li> <li id="fn2">This key consists of 16 <code>0x31</code> bytes followed by 16 <code>0x00</code> bytes. <a href="#fnref2" class="footnote-backlink" role="doc-backlink">[↩︎]</a></li> </ol> </div> <p>During the T1M scan, after AWS and Stackpath have resolved the issue, we found three further hosts using an all-zero key for both encryption and HMAC. These hosts used AES-128-CBC with HMAC-SHA256 and supported TLS 1.2. One of these hosts also supported TLS 1.3, also using zero-keys for session tickets.</p> <p>As can be seen in the table, with our subsequent IPF scan we could detect more interesting keys. We found 189 servers using a weak key. Out of these, 111 servers were using an all-zero key. For 5 hosts we did not detect a weak key for the HMAC algorithm. 12 hosts used SHA384, which no analyzed open-source library uses. This implies, they use a different implementation or reconfigured the used library. The remaining 78 servers did not use keys that solely consisted of zero bytes. We explore the detected keys in our paper.</p> <h2 id="impact">Impact</h2> <p>The presented issues allowed to decrypt TLS session tickets. This allows a passive adversary to decrypt all resumed sessions. In TLS 1.2 this even allows decrypting the session where the ticket was issued, even if it was never resumed. TLS 1.3 mitigates parts of this issue by deriving the keys for the new session using a one-way function instead of plainly reusing them. This means, even if the ticket is decrypted, the attacker cannot decrypt the resumed session. Further, TLS 1.3 allows performing another key exchange when resuming a session. After this key exchange, the encrypted data is secure against a passive adversary again. This still leaves the 0-RTT data vulnerable to decryption.</p> <p>All versions are vulnerable to active impersonation. An attacker able to decrypt the session ticket can impersonate the server as the authentication solely relies on the ticket. The server does not send a certificate or signature, hence the client cannot verify the identity of the server. This undermines the security guarantees of TLS.</p> <p>As of now, we have not released a version of TLS-Scanner that can test whether you are affected by this issue. We plan on releasing it in time for the artifact evaluation for Usenix (June-August).</p> <h2 id="takeaways">Takeaways</h2> <p>We showed that improper usage of session tickets can have devastating consequences for TLS connections and break forward secrecy guarantees delivered by TLS. The concrete issues discovered seem unlikely, but are an important reminder that looking for seemingly trivial or contrived issues can be worthwhile for auditors.</p> <p>At its core, we attribute the observed issues to the unauditability of session tickets. Since the STEK and the layout are unknown and never revealed to the client, clients cannot simply validate the strength of the key, the presence of a MAC, or even the algorithms used. This lack of transparency creates a space for bad implementations, silently failing crypto, and hidden backdoors.</p> <p>While key generation always seems to have this potential, it is especially severe for one-sided symmetric keys, as with asymmetric keys, at least the public key can be audited externally <d-cite key="USS:180213, USENIX:SNSKFKM16"></d-cite>. Having hard-to-analyze keys in a protocol at a place where a weak or leaked key causes the protocol to fail catastrophically is a huge risk that requires careful consideration. Since these keys cannot be audited externally, we argue that libraries should start auditing them themselves before they use them.</p> <p>In public key cryptosystems, it is already common practice to ensure that the generated key material is of a specific form, for example, to ensure that the key material will result in a strong key or as a safety net for failing random number generators. Adding additional checks to randomly drawn symmetric keys could, at least to some extent, ensure that accidentally weak key material does not break the protocol.</p> <h3 id="further-results">Further Results</h3> <p>In our paper, we have seen a single case of a reused nonce. As we did not perform a long time study, we cannot say whether this is a one-time issue or a more general problem. We argue that libraries should use nonce reuse-resistant algorithms to avoid this issue. In general misuse-resistant APIs should be developed and enforced.</p> <p>We cover further attacks that can be applicable to session tickets in our paper. We also present the analysis of open-source implementations and their usage of session tickets. See our preprint for more details:</p> <div style="text-align: center;"> <p><a href="https://www.usenix.org/conference/usenixsecurity23/presentation/hebrok"><strong>We Really Need to Talk About Session Tickets:<br/>A Large-Scale Analysis of Cryptographic Dangers with TLS Session Tickets</strong></a> <br/> <a href="https://twitter.com/xoimex">Sven Hebrok</a>, <a href="https://twitter.com/snachti">Simon Nachtigall</a>, <a href="https://twitter.com/marcelmaehren">Marcel Maehren</a>, <a href="https://twitter.com/nerinola1">Nurullah Erinola</a>, <br/> <a href="https://twitter.com/ic0nz1">Robert Merget</a>, <a href="https://twitter.com/jurajsomorovsky">Juraj Somorovsky</a>, <a href="https://twitter.com/JoergSchwenk">Jörg Schwenk</a></p> </div>]]></content><author><name>Sven Hebrok</name></author><summary type="html"><![CDATA[A Large-Scale Analysis of Cryptographic Dangers with TLS Session Tickets]]></summary></entry><entry><title type="html">Bachelor’s Thesis: Web Key Directory and Other Key Exchange Methods for OpenPGP</title><link href="https://upb-syssec.github.io/blog/2023/web-key-and-other-key-exchange-methods-for-openpgp/" rel="alternate" type="text/html" title="Bachelor’s Thesis: Web Key Directory and Other Key Exchange Methods for OpenPGP"/><published>2023-03-06T00:00:00+00:00</published><updated>2023-03-06T00:00:00+00:00</updated><id>https://upb-syssec.github.io/blog/2023/web-key-and-other-key-exchange-methods-for-openpgp</id><content type="html" xml:base="https://upb-syssec.github.io/blog/2023/web-key-and-other-key-exchange-methods-for-openpgp/"><![CDATA[ <style>html[data-theme="dark"] img.wkd-dark-invert{filter:invert(1)}</style> <p>Philipp Breuch completed his Bachelor’s degree at Paderborn University in August, 2022. He wrote his Bachelor’s Thesis “Web Key Directory and Other Key Exchange Methods for OpenPGP” <d-cite key="Breuch:22:BA-WKD"></d-cite> at the System Security Research Group supervised by Prof. Dr.-Ing. Juraj Somorovsky and Dipl.-Math. Marcus Brinkmann.</p> <hr/> <p>OpenPGP is used in various different application areas like securing mails, encrypting files, and validating the integrity and authenticity of exchanged files. A core design principle of OpenPGP is decentralization. In contrast to cryptographic protocols utilizing the public key infrastructure (e.g., S/MIME in the context of securing mails, or HTTPS for web), OpenPGP has no centralized trust anchors.</p> <p>As direct key distribution and key validation do not scale, the OpenPGP ecosystem evolved two indirect concepts:</p> <ul> <li><strong>key servers</strong> for key distribution</li> <li>the <strong>Web of Trust</strong> as a decentralized trust model for validating the authenticity of keys</li> </ul> <p>It turned out that both concepts have fundamental problems:</p> <ul> <li>Key servers do not verify uploaded keys. Everyone can upload keys for any e-mail address, which leads to different attack vectors. For example, the “evil32” attack <d-cite key="evil32"></d-cite> showed that it is very efficient to generate and upload keys with the same short fingerprint (the last 4 bytes of the full fingerprint). Users who check only the short fingerprint can not distinguish between the legitimate and the counterfeit key.</li> <li>To make the “web of trust” possible, users can sign a specific public key to express its validity. However, this process can also be exploited by an attacker; if they massively sign and upload a victim’s key to a key server, the key size will grow steadily. As a result, a key with too many signatures (the specific amount depends on the used software) can not be processed anymore. Synchronizing key servers are practically only appending key material, which complicates mitigation of such attacks.</li> <li>Not only manipulated keys, but also public keys where users no longer possess the corresponding private key, remain in the system.</li> <li>It turned out that only a fraction of the users of the “web of trust” can significantly profit from it <d-cite key="Ulrich:11:IWoT"></d-cite>. This is contrasted by the disclosure of personal data and the social graphs of the users, which can be derived from the key signatures.</li> <li>The SKS key server network, which was used as the default key server in GnuPG, is no longer maintained and has been shutdown on 2021-06-21 due to privacy problems and legal problems resulting from the European General Data Protection Regulation.</li> </ul> <p>An approach to improve this situation is Web Key Directory. It provides a method to associate OpenPGP keys to a well-known URI and distribute them over HTTPS. Web Key Directory incorporates security properties of the TLS ecosystem by the use of HTTPS for key exchange. Trusting exchanged keys over this method, therefore, implies trusting in TLS and the (web)server responsible for the publication.</p> <h2 id="in-a-nutshell-web-key-directory">In a Nutshell: Web Key Directory</h2> <p>Web Key Directory (WKD) <d-cite key="koch-openpgp-webkey-service-14"></d-cite> is an IETF Internet Draft which consists of two protocols, which will be briefly described here before presenting the results of the security analysis:</p> <ol> <li>The Key Discovery Protocol can be used to discover and receive OpenPGP keys published via the Web Key Directory.</li> <li>The Directory Update Protocol can be used to submit keys in an automated, e-mail driven way to the Web Key Directory.</li> </ol> <h3 id="key-discovery-protocol">Key Discovery Protocol</h3> <p>Web Key Directory associates keys with their e-mail addresses. These keys are provided by a webserver on the domain of the e-mail address. To locate and request a key, the client sends a GET request over an HTTPS secured connection to this webserver. There are two variants of URIs, the <em>advanced</em> and the <em>direct</em> variant.</p> <p>In the following, we look briefly at the URI constructed for the e-mail address <em>Alice.Wonderland@example.org</em> in the advanced variant:</p> <p><img src="/assets/img/web-key-and-other-key-exchange-methods-for-openpgp_-_wkd-uri-advanced.svg" alt="An annotated example of a WKD URL. The domain is the 'openpgpkey' subdomain of the e-mail address domain. The last part of the path is the Z-Base-32 encoded SHA-1 hash of the lower-case local-part of the e-mail address. The GET parameter 'l' has the local-part of the e-mail address with URI percentage encoding as needed. The complete example URI is: https://openpgpkey.example.org/.well-known/openpgpkey/example.org/hu/5gt5gnaq1zccz7f19kq9whu4ezf1uofq?l=Alice.Wonderland" width="100%" class="wkd-dark-invert"/></p> <p>We see that most of the URI construction is pretty straight-forward. The second variant, the direct URI, is only used if the <em>openpgp</em> subdomain does not exist and is simply the advanced URI omitting the subdomain and the repetition of the e-mail address domain in the path. The response to this HTTPS GET request is the OpenPGP key for the given e-mail address, regardless of URI variant.</p> <p>Some attention should be lent to the last part of the path, which is the local-part of the e-mail address, mapped to lower-case, hashed, and encoded in alpha-numerical characters (e.g., a hash of “alice.wonderland”). This is done in part to ease the implementation of WKD servers by ensuring this path element is always a valid file name without special characters that might be rejected, for example, by the webserver’s operating system. However, it is not strictly compliant to the e-mail specification to treat the local-part always case-insensitive; but it reflects the typical real-world usage of e-mail addresses.</p> <p>Therefore, if a Web Key Directory should be provided for an e-mail server that distinguishes e-mail addresses by case, the WKD server has to make sure to check the verbatim local-part in the <code class="language-plaintext highlighter-rouge">l</code> parameter. Otherwise e-mail addresses which only differ in case would be mapped to the same key. This could make it possible to publish an OpenPGP key for all of those e-mail addresses by only possessing one.</p> <h3 id="update-protocol">Update Protocol</h3> <p>The purpose of the e-mail driven update protocol is to automate and ease the publication process of OpenPGP keys to the Web Key Directory. It is based primarily on OpenPGP secured e-mail exchange between the user and their Web Key Directory provider.</p> <p>For the submission process, we need to know the submission e-mail address to which we submit our key and the OpenPGP key for that submission address. The submission address is defined in a file which is served by the Web Key Directory webserver. The corresponding key is treated like every other published key and can therefore be requested via the key discovery protocol.</p> <p>To ensure that only the legitimate key owner can publish their keys, the update protocol uses a challenge-response mechanism.</p> <p><img src="/assets/img/web-key-and-other-key-exchange-methods-for-openpgp_-_wkd-update-protocol.svg" alt="Exchanged e-mails in the WKD Update Protocol between user Alice and her WKD provider in a Message Sequence Graph. First, Alice sends a submission mail to her WKD provider. This submission mail is encrypted to the WKD provider and contains the key with one User-ID (e-mail address). Second, the WKD provider sends a confirmation request to the e-mail address of the submitted key (i.e. Alice). This confirmation request mail is encrypted to the submitted key and signed by the WKD provider. It contains the e-mail address, the fingerprint of the submitted key, and the nonce as a secret. Third, Alice sends a confirmation response back to the WKD provider. This confirmation response is encrypted to the WKD provider and signed by Alice. It contains the e-mail address and the nonce. Fourth, the WKD provider publishes the submitted key to the Web Key Directory and notifies Alice via an optional success mail." width="100%" class="wkd-dark-invert"/></p> <p>This mechanism is implemented via the confirmation request and confirmation response mails. The confirmation request is sent to the e-mail address of the submitted key and is encrypted with the submitted key and signed by the WKD provider. The critical contents are the randomly chosen nonce as the secret, the e-mail address and fingerprint of the submitted key. E-mail address and fingerprint can be used by the user to verify that the correct key should be published for the correct e-mail address.</p> <p>The nonce is only accessible by the key owner because they should be the only person in possession of the corresponding private key and thus able to decrypt the nonce. If the nonce is sent back correctly, the server can assume that the key owner wants to publish the submitted key and makes the key available via the Web Key Directory. The server can send an optional success message to the user.</p> <p>The challenge-response mechanism has to be done with the person for which the key should be published for. But how do we know that the key supposedly for <em>alice@example.org</em> is indeed from Alice and not from an attacker like Mallory? The update protocol is based on the assumption that the WKD provider can securely deliver mail to the owner of the mail address without third-parties able to read its contents. We will address this assumption below in the security analysis.</p> <h2 id="security-analysis">Security Analysis</h2> <p>During the analysis, it became apparent that we had to distinguish between the Web Key Directory specification and the reference implementation (<a href="https://git.gnupg.org/cgi-bin/gitweb.cgi?p=gnupg.git;a=tags">GnuPG 2.2.35 (LTS)/ 2.3.6</a>) in regard to the security implications. Regarding the WKD specification we found one major concern in the lax and vague main assumption for the update protocol. The <em>GnuPG</em> implementation of WKD is the only implementation we know about which tries to implement both the discovery and update protocol. We found several implementation errors and faults in this implementation, which were not always security relevant. However, a combination of two errors made it possible to find an attack which allowed us to completely compromise a Web Key Directory installation.</p> <h3 id="update-protocol-main-assumption">Update Protocol Main Assumption</h3> <p>The main assumption regarding the security of the WKD Update Protocol reads as follows:</p> <blockquote> <p>The protocol defined here is entirely based on mail and the assumption that a mail provider can securely deliver mail to the INBOX of a user (e.g., an IMAP folder).</p> </blockquote> <p>This assumption is vague and unclear. It is neither clear which security properties are requested nor from whom. E-mail infrastructure can be very complex. An e-mail from a Web Key Directory provider to their user might take several hops before reaching its destination.</p> <p>We created three scenarios how the e-mail infrastructure topology could look like and considered several interpretations of the main assumption. We examined these interpretations with the topology scenarios and discussed their impact on the security of WKD.</p> <p>Only in one interpretation we could find no attack points in any scenario. This interpretation, however, was the most unrealistic: the assumption, that a mail provider can “securely” (i.e. at least confidentially) deliver e-mails to the inbox of the recipient user’s mail client, even for recipients on other servers.</p> <p>The security of the update protocol should not be based on such a vague assumption. Our discussion showed potential attack points which might also exist in real-world setups. For details see Thesis Section 6.3.</p> <h3 id="implementation-errors-and-faults">Implementation Errors and Faults</h3> <p>We found out that the reference implementation is not completely specification-compliant. This is due to not implementing requirements of the specification correctly or at all. In addition there are two MIME headers (<code class="language-plaintext highlighter-rouge">Wks-Phase</code>, <code class="language-plaintext highlighter-rouge">Wks-Draft-Version</code>) in each message of the reference implementation which are not specified. These headers are not secured (e.g., integrity-protected) in any way. Problematic is the use of the <code class="language-plaintext highlighter-rouge">Wks-Draft-Version</code> header because it makes the reference implementation mostly incompatible to specification-compliant implementations. The reference implementation decides which WKD specification version is used for the processed mail based on this header. However, this header could easily be changed which could open potential possibilities for downgrade attacks on future protocol changes.</p> <p>In addition, we found further conceptual and implementation errors like missing and incorrect signature generation and verification in the reference implementation. The confirmation response may be sent unencrypted and attacker controlled data like <code class="language-plaintext highlighter-rouge">nonce</code> and <code class="language-plaintext highlighter-rouge">address</code> fields in the mails are not checked properly. See section 6.4 in the thesis for more information.</p> <h3 id="attack-on-the-update-protocol-implementation">Attack on the Update Protocol Implementation</h3> <p>Two of the above implementation errors led to a vulnerability, which allowed an attacker to publish OpenPGP keys for <strong>any</strong> e-mail address for <strong>any</strong> domain managed by a Web Key Directory provider. Assume an attacker Mallory wants to publish a self generated key impersonating Alice to their WKD provider. This attack has almost no assumptions:</p> <ol> <li>Victim Alice has an e-mail address like <a href="mailto:alice@example.net">alice@example.net</a></li> <li>Attacker Mallory has an e-mail address like <a href="mailto:mallory@example.org">mallory@example.org</a></li> <li>The Web Key Directory provider uses <ul> <li>the GnuPG implementation of WKD</li> <li>provides the WKD for both domains example.net and example.org</li> <li>provides the WKD Update Protocol</li> </ul> </li> </ol> <p>The attack also works with Alice and Mallory using e-mail addresses with the same domain.</p> <p>The attack is demonstrated in the below picture of the update protocol run:</p> <p><img src="/assets/img/web-key-and-other-key-exchange-methods-for-openpgp_-_wkd-update-protocol-attack.svg" alt="Attack on the Update Protocol shown as a Message Sequence Graph. It is similar to the Message Sequence Graph for the WKD Update Protocol (from above) but users are Alice, Mallory, and the WKD Provider. Mallory submits a key and then participates in the challenge-response mails with the server. Alice receives only an encrypted confirmation request and the optional success message after successful publication of the submitted key. Parts in the graph which are changed by Mallory in comparison to the regular WKD Update Protocol run are highlighted. These are the submitted key which contains both a User-ID for Alice and for Mallory, as well as the changed address and nonce fields in the confirmation response." width="100%" class="wkd-dark-invert"/></p> <p>Mallory submits a key to the WKD provider with two User-IDs (i.e. names/addresses assigned to the key): one User-ID for alice@example.net and one for mallory@example.org. It turned out that the GnuPG implementation sends a confirmation request to each of these e-mail addresses. Each of these contain the distinct e-mail address in the <code class="language-plaintext highlighter-rouge">address</code> field, a distinct <code class="language-plaintext highlighter-rouge">nonce</code>, and the same <code class="language-plaintext highlighter-rouge">fingerprint</code> (key is the same for both). Mallory is in possession of the private key and can decrypt the confirmation request to send a confirmation response back to the server. Mallory must achieve two goals to succeed:</p> <ol> <li>The server has to believe the confirmation response is for a confirmation request for Alice</li> <li>The server has to see the nonce in the confirmation response as valid for a confirmation request for Alice.</li> </ol> <p>The first goal is quite simple. The <code class="language-plaintext highlighter-rouge">address</code> field is not protected or validated and Mallory changes it simply in her confirmation response from mallory@example.org to alice@example.net. The second goal is not that simple because Mallory does not know the nonce sent to Alice. By digging into the source code we found that the nonce in the <code class="language-plaintext highlighter-rouge">nonce</code> field is not checked directly: The nonce sent in the confirmation response is <em>not</em> compared with the nonce in the confirmation request. Instead the existence of a file path created with the nonce is checked. The path consists of the following: ‘<strong>domain / “pending” / nonce</strong>’. The domain is taken from the <code class="language-plaintext highlighter-rouge">address</code> field, “pending” is a fixed string, and the nonce is the value of the <code class="language-plaintext highlighter-rouge">nonce</code> field. Both fields are not sanitized.</p> <p>So, great! We can bend the path to every location in the file system via a simple path traversal on the <code class="language-plaintext highlighter-rouge">nonce</code> field.</p> <p>To understand how our path traversal has to look like, we will have to look at how the implementation handles submitted keys internally:</p> <p><img src="/assets/img/web-key-and-other-key-exchange-methods-for-openpgp_-_wkd-directory.svg" alt="A directory tree containing paths like example.net/pending/o3euik... and example.org/pending/7mpzp4..., with example.net being the domain used by Alice and example.org the domain used by Mallory." width="100%" class="wkd-dark-invert"/></p> <p>The implementation can handle a Web Key Directory for multiple e-mail address domains. Each domain has its own directory. In this directory there is, for example, the <code class="language-plaintext highlighter-rouge">hu</code> directory which contains all published keys. Submitted but not yet verified keys are stored in the <code class="language-plaintext highlighter-rouge">pending</code> directory and named after the nonce used in the confirmation request.</p> <p>Mallory submitted a key with two User-IDs (one for Alice and one for her). The complete key is stored twice: once in the pending directory for example.net named after the nonce only send to Alice <em>(o3euik3tr3d6rjwr…)</em>; once in the pending directory for example.org named after the nonce only send to Mallory <em>(7mpzp4cgkr5uy3bz…)</em>.</p> <p>Based on the path creation and the file structure we can see that a path traversal string ‘<strong>../../example.org/pending/</strong>’ has to be prepended to the nonce in the confirmation response. The resulting path ‘<strong>example.net/pending/../../example.org/pending/7mpzp4cgkr5uy3bz…</strong>’ exists and contains the full submitted key. The implementation will then publish the key (with only the User-ID of Alice) as the key for <em>alice@example.net</em>.</p> <p>Thus we have an attack to publish a key for <em>any</em> e-mail address of <em>any</em> domain on a Web Key Directory. The path traversal indeed is only necessary if the domain used by Alice and Mallory differs. Otherwise the changed address field would be sufficient to accomplish the attack. This issue has been fixed in GnuPG version 2.2.37.</p> <h2 id="conclusion">Conclusion</h2> <p>In this blog post we have seen a brief overview of the two Web Key Directory Protocols. We presented an attack based on improper checking of the nonce and missing input sanitization which allows publishing of illicit public keys for all e-mail addresses for all domains a Web Key Directory manages. While this has been fixed, other issues like the update protocol main assumption might not be as easy to fix. The GnuPG authors don’t seem to consider issues like signature verification as important to fix, either.</p>]]></content><author><name>Philipp Michael Breuch</name></author><summary type="html"><![CDATA[a security analysis on the OpenPGP key exchange method Web Key Directory]]></summary></entry><entry><title type="html">Usage Statistics of 3D Printing File Formats</title><link href="https://upb-syssec.github.io/blog/2022/3d-printing-file-format-usage/" rel="alternate" type="text/html" title="Usage Statistics of 3D Printing File Formats"/><published>2022-12-02T00:00:00+00:00</published><updated>2022-12-02T00:00:00+00:00</updated><id>https://upb-syssec.github.io/blog/2022/3d-printing-file-format-usage</id><content type="html" xml:base="https://upb-syssec.github.io/blog/2022/3d-printing-file-format-usage/"><![CDATA[<p>During our current research on the security of 3D printers and the surrounding ecosystem, we asked ourselves how well different file formats are used. As there seems to be no clear data, just anecdotal evidence, we decided to check for ourselves.</p> <p>We analyze which are the most used file formats on two popular 3D model online-marketplaces, namely <a href="https://www.thingiverse.com/">Thingiverse</a> and <a href="https://www.myminifactory.com/">MyMiniFactory</a>. The data presented here is based on the publicly available files uploaded to both platforms. The data does not contain any information about the usage of different file formats outside this specific use case of private users sharing their 3D printing model with others; especially not regarding an industrial context. No other data is freely available. The <a href="#how-to-get-the-data">How to Get the Data</a> section below provides download links and how-tos for our dataset. The data presented here was collected in June 2021.</p> <h2 id="how-we-collected-the-data">How We Collected the Data</h2> <p>Both <em>Thingiverse</em> and <em>MyMiniFactory</em> provide application programming interfaces (APIs) that allow access to their data sets, specifically JSON-based HTTP REST APIs <d-cite key="rfc8259,rfc2616,fielding2000architectural,MyMiniFactoryAPIDocumentation,thingiverse.comRESTAPIReference"></d-cite>. In both cases, there is no API endpoint to list existing objects, but both websites use incrementing numbers to identify the objects. Thus, gathering a complete data set is a matter of incrementally trying every number until no more objects are found. This can be done for both marketplaces. For both marketplaces, we incremented the object IDs and attempted to download the JSON metadata for the ID.</p> <p>The data set for <em>Thingiverse</em> contains more than two million entries, where the set for <em>MyMiniFactory</em> amounts to roughly 130,000 entries. For each object the downloaded metadata includes the file names of all files uploaded to that object. To ease the analysis, we stored the uploaded file names and their upload timestamp for each object. Then, we reduced the file name to their suffix(es) (i.e. their file extension) and unified the them to a lower case version. This means our analysis is limited to the knowledge derived from the file suffixes the uploader used. It might be the case that the uploaded file does not match the actual content. Additionally, we do not analyze the content of uploaded <code class="language-plaintext highlighter-rouge">.zip</code> (or similar) files.</p> <h2 id="overview-of-the-data">Overview of the Data</h2> <p><a href="#tab:file-format-occurrences">Table 1</a> lists the file formats that occur the most often in our data sets.<d-footnote>All file formats that occur more than 10,000 times. The remaining files account for 8% of all files.</d-footnote> <em>Total Occurrences</em> shows the sum of all files uploaded for every object. Multiple files of the same format can be uploaded for the same object. That explains why the number of STL files can exceed that of the total number of objects in the data sets by about a factor of four. There are more than five times as many STL files uploaded than all other file uploads combined.<d-footnote>There are 4,592,742 STL files and 787,577 other files in total.</d-footnote> The <em>Repetition Factor</em> indicates how many files of the same format are uploaded for the same object on average. For each format, we only counted objects where the given file format was present at least once. Hence, the minimal value of the repetition factor is one. Most repetition values are higher than 1.5 which shows that most file formats are rarely uploaded on their own. That can be attributed to different variants of the same model being uploaded, for example, different scalings or colors. The difference in the repetition factor between formats might be caused by limitations of the format itself or by common practices.</p> <div class="l-body-outset"><hr/></div> <style>.footnote-ref{color:var(--global-theme-color)!important;border-bottom:0;text-decoration:none}.distill-fn-style li{color:var(--global-distill-app-color)!important;font-size:.8em;line-height:1.7em}.distill-fn-style a{color:var(--global-distill-app-color)!important;border-bottom:0;text-decoration:none}.distill-fn-style a:hover{color:var(--global-hover-color)!important;border-bottom:0;text-decoration:none}</style> <p><span id="tab:file-format-occurrences"><strong>Table 1</strong></span> Total number of occurrences/uploads of all file formats that occur more than 10,000 times. The suffixes where unified to their lower-case version an the following suffixes were omitted: <code class="language-plaintext highlighter-rouge">.pdf</code>, <code class="language-plaintext highlighter-rouge">.zip</code>, <code class="language-plaintext highlighter-rouge">.0</code>, <code class="language-plaintext highlighter-rouge">.1</code>, <code class="language-plaintext highlighter-rouge">.svg</code>. AMF is included as it is mentioned by various rankings <d-cite key="3DPrinterFile2021,Common3DPrinting2019,WhatFileFormats2021"></d-cite>. The repetition factor indicates how many files of this type were uploaded to a single object on average.</p> <table> <thead> <tr> <th>Suffix</th> <th>File Format Description</th> <th style="text-align: right">Total Occurrences</th> <th style="text-align: right">Repetition Factor</th> </tr> </thead> <tbody> <tr> <td><code class="language-plaintext highlighter-rouge">.stl</code></td> <td>STereoLithography <sup><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref">a</a></sup></td> <td style="text-align: right">4,592,742</td> <td style="text-align: right">2.13</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.scad</code></td> <td><a href="http://openscad.org/">OpenSCAD</a> project file</td> <td style="text-align: right">77,585</td> <td style="text-align: right">1.42</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.obj</code></td> <td>Wavefront Object <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>b</sup></a></td> <td style="text-align: right">65,556</td> <td style="text-align: right">1.86</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.step</code></td> <td><span><em>STandard for the Exchange of Product model data</em> <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>c</sup></a></span></td> <td style="text-align: right">44,920</td> <td style="text-align: right">1.72</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.sldprt</code></td> <td><a href="https://www.solidworks.com/">SolidWorks</a> Part file</td> <td style="text-align: right">43,599</td> <td style="text-align: right">2.00</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.skp</code></td> <td><a href="https://www.sketchup.com/">SketchUp</a> project file</td> <td style="text-align: right">32,522</td> <td style="text-align: right">1.48</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.f3d</code></td> <td><a href="https://www.autodesk.com/products/fusion-360">Fusion 360</a> project file</td> <td style="text-align: right">32,275</td> <td style="text-align: right">1.30</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.fcstd</code></td> <td><a href="https://www.freecadweb.org/">FreeCAD</a> project file</td> <td style="text-align: right">21,436</td> <td style="text-align: right">1.52</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.dxf</code></td> <td><em>Drawing Interchange File</em> for <em>AutoCAD</em> <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>d</sup></a></td> <td style="text-align: right">20,566</td> <td style="text-align: right">1.94</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.gcode</code></td> <td>Toolpath instruction for manufacturing devices <a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>e</sup></a></td> <td style="text-align: right">16,713</td> <td style="text-align: right">1.52</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.ipt</code></td> <td><a href="https://www.autodesk.com/products/inventor">Inventor</a> project file</td> <td style="text-align: right">14,905</td> <td style="text-align: right">1.96</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.3mf</code></td> <td>3D Manufacturing Format <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>f</sup></a></td> <td style="text-align: right">14,823</td> <td style="text-align: right">1.63</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.blend</code></td> <td><a href="https://www.blender.org/">Blender</a> project file</td> <td style="text-align: right">13,720</td> <td style="text-align: right">1.61</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.123dx</code></td> <td><a href="https://www.autodesk.com/solutions/123d-apps">123D</a> project file <a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>g</sup></a></td> <td style="text-align: right">12,146</td> <td style="text-align: right">1.55</td> </tr> <tr> <td>︙</td> <td>︙</td> <td style="text-align: right">︙</td> <td style="text-align: right">︙</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">.amf</code></td> <td>Additive Manufacturing Format <a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>h</sup></a></td> <td style="text-align: right">2,451</td> <td style="text-align: right">1.54</td> </tr> </tbody> </table> <ol class="distill-fn-style" type="a"> <li id="fn1">Defined by <i>3D Systems</i> in 1988 <d-cite key="STLSTereoLithographyFile2019"/>. The original specification is not available, but various resources describe the format based on the original specification<d-cite key="STL,STLAFilesASCII,StLFormatFabbers"/>. <a href="#fnref1" class="footnote-backlink" role="doc-backlink">[↩︎]</a></li> <li id="fn2">First specified by <i>Wavefront Technologies</i> for their <i>Advanced Visualizer</i> software in the 1990s <d-cite key="wavefronttechnologiesAdvancedVisualizerAppendixearly1990s"/>. “[From] a legal standpoint, the specification is probably proprietary to Autodesk” <d-cite key="WavefrontOBJFile2020"/> as Wavefront Technologies was eventually indirectly acquired by Autodesk <d-cite key="WavefrontOBJFile2020"/>. <a href="#fnref2" class="footnote-backlink" role="doc-backlink">[↩︎]</a></li> <li id="fn3">Designed as an exchange format between CAD applications. Standardized through the ISO 10303 family <d-cite key="iso10303-1"/>, part 21 <d-cite key="iso10303-21"/> defines the file format. Alternatively, uses the suffix <code>.stp</code>. <a href="#fnref3" class="footnote-backlink" role="doc-backlink">[↩︎]</a></li> <li id="fn4">Designed as an exchange format between CAD applications. Standardized by Autodesk for their AutoCAD software <d-cite key="dxf"/>. <a href="#fnref4" class="footnote-backlink" role="doc-backlink">[↩︎]</a></li> <li id="fn5">There are multiple standards defining G-codes (e.g. <d-cite key="din66025-1,iso6983-1"/>) but most applications and/or firmwares define their own extensions and variations. <a href="#fnref5" class="footnote-backlink" role="doc-backlink">[↩︎]</a></li> <li id="fn6">The specification <d-cite key="3MF-core"/> is created by the 3MF Consortium. The first version of the specification was published in 2015. The specification is open-source and managed in a Git repository. The specification was not uploaded to GitHub until 2018 (Version 1.2) <d-cite key="3MF-core"/>. <a href="http://web.archive.org/web/20160320020131/https://3mf.io/wp-content/uploads/2015/04/3MFcoreSpec_1.0.1.pdf">Version 1.0 was initially uploaded to the 3MF Consortium’s website</a> but has since been removed.<a href="#fnref6" class="footnote-backlink" role="doc-backlink">[↩︎]</a></li> <li id="fn7">Discontinued by AutoDesk in 2016. <a href="http://web.archive.org/web/20150430070500/http://www.123dapp.com/">Original Webpage</a>. <a href="#fnref7" class="footnote-backlink" role="doc-backlink">[↩︎]</a></li> <li id="fn8">Initially proposed as “STL 2.0” by Hiller et.al. <d-cite key="hillerSTLProposalUniversal2009"/>. Since the initial proposal, it has been jointly specified by ISO &amp; ASTM <d-cite key="iso52915"/>. <a href="#fnref8" class="footnote-backlink" role="doc-backlink">[↩︎]</a></li> </ol> <div class="l-body-outset"><hr/></div> <p>Overall, only 3% of objects do not have an associated STL file.<d-footnote>In total about 56,000 objects.</d-footnote> The top three file formats of objects where no STL is uploaded are <code class="language-plaintext highlighter-rouge">.obj</code>, <code class="language-plaintext highlighter-rouge">.scad</code>, and <code class="language-plaintext highlighter-rouge">.dxf</code>. Further, nine of the fifteen listed files are project files for specific programs. Together these facts suggest that the most common use case is for a user to upload an STL file and their project file of the software they created the STL with. Alternatively, the model is uploaded as an OBJ file, or in popular exchange file formats for Computer Aided Design (CAD) software (i.e. <code class="language-plaintext highlighter-rouge">.scad</code> and <code class="language-plaintext highlighter-rouge">.dxf</code>).</p> <h2 id="trend-of-usage-over-time">Trend of Usage over Time</h2> <p>To get an overview of the change in usage we plotted the uploads per month of each file format.</p> <p>As some file formats support multiple models in one file and others do not, we ignore duplicate suffixes on files for the same object that were uploaded on the same day. This sanitization is required, as otherwise there might be biases towards the formats that do not support multiple models in one file, as a user would have to upload multiple files for a complex model with separated parts. This reduces the variance in the repetition factor from <a href="#tab:file-format-occurrences">Table 1</a>.</p> <p>As you can see in the graph below, <code class="language-plaintext highlighter-rouge">.obj</code>, <code class="language-plaintext highlighter-rouge">.step</code>, and <code class="language-plaintext highlighter-rouge">.f3d</code> all follow a near identical curve that shows rapid increases in usage. <code class="language-plaintext highlighter-rouge">.3mf</code> shows fewer usage overall, but a rapid increase since its initial release. <code class="language-plaintext highlighter-rouge">.sldprt</code>, <code class="language-plaintext highlighter-rouge">.fcstd</code>, <code class="language-plaintext highlighter-rouge">.dxf</code>, <code class="language-plaintext highlighter-rouge">.gcode</code>, and <code class="language-plaintext highlighter-rouge">.blend</code> show a more steady growth. <code class="language-plaintext highlighter-rouge">.ipt</code> and <code class="language-plaintext highlighter-rouge">.amf</code> both fluctuate more than others and seem more or less stagnant. <code class="language-plaintext highlighter-rouge">.skp</code>, <code class="language-plaintext highlighter-rouge">.123dx</code> are declining in usage. In the case of <code class="language-plaintext highlighter-rouge">.123dx</code> this is expected, since AutoDesk discontinued the 123D program suite in 2016.</p> <div class="l-page"> <canvas id="usageOverTime"></canvas> </div> <style>.btn{border:0;display:inline-block;border:0;padding:3px 16px;vertical-align:middle;background-color:var(--global-code-bg-color);text-align:center;cursor:pointer;white-space:nowrap}.btn:hover{box-shadow:0 4px 8px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}</style> <p><button type="button" id="yAxisButton" class="btn" style="width: calc(100% - 10em); margin-left: 5em; margin-top: 1em;">make X axis linear</button></p> <script src="https://cdn.jsdelivr.net/npm/chart.js@4.0.1/dist/chart.umd.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/moment@2.29.4/moment.min.js"></script> <script>var chart,button=document.querySelector("#yAxisButton"),buttonClick=button&&button.addEventListener("click",function(){chart&&("logarithmic"==chart.options.scales.yAxes[0].type?(button.textContent="make X axis logarithmic",chart.options.scales.yAxes[0].type="linear"):(button.textContent="make X axis linear",chart.options.scales.yAxes[0].type="logarithmic"),chart.update())});fetch("/assets/data/3d-printing-file-format-usage/format_uploads_per_month_per_object.json").then(o=>o.json()).then(function(o){function a(a){return Array.from(o.months,(e,t)=>({x:e,y:o.data[a][t]}))}const e=document.getElementById("usageOverTime");color_map=["#1ba3c6","#2cb5c0","#30bcad","#21B087","#33a65c","#57a337","#a2b627","#d5bb21","#f8b620","#f89217","#f06719","#e03426","#f64971","#fc719e","#eb73b3","#ce69be","#a26dc2","#7873c0","#4f7cba"],chart=new Chart(e,{type:"line",data:{labels:o.months,datasets:[{label:".stl",data:a(".stl"),borderColor:color_map[0]},{label:".scad",data:a(".scad"),hidden:!0,borderColor:color_map[1]},{label:".obj",data:a(".obj"),borderColor:color_map[2]},{label:".step/.stp",data:Array.from(o.months,(a,e)=>({x:a,y:o.data[".step"][e]+o.data[".stp"][e]})),hidden:!0,borderColor:color_map[3]},{label:".sldprt",data:a(".sldprt"),hidden:!0,borderColor:color_map[4]},{label:".skp",data:a(".skp"),hidden:!0,borderColor:color_map[5]},{label:".f3d",data:a(".f3d"),hidden:!0,borderColor:color_map[6]},{label:".fcstd",data:a(".fcstd"),hidden:!0,borderColor:color_map[7]},{label:".dxf",data:a(".dxf"),hidden:!0,borderColor:color_map[8]},{label:".gcode",data:a(".gcode"),hidden:!0,borderColor:color_map[9]},{label:".ipt",data:a(".ipt"),hidden:!0,borderColor:color_map[10]},{label:".3mf",data:a(".3mf"),borderColor:color_map[11]},{label:".blend",data:a(".blend"),hidden:!0,borderColor:color_map[12]},{label:".123dx",data:a(".123dx"),hidden:!0,borderColor:color_map[13]},{label:".amf",data:a(".amf"),borderColor:color_map[14]}]},options:{scales:{yAxes:[{scaleLabel:{display:!0,labelString:"Number of Uploads per File Format per Month"},type:"logarithmic",position:"left"}],xAxes:[{scaleLabel:{display:!0,labelString:"Time"},type:"time"}]},elements:{point:{radius:0},line:{borderWidth:2,fill:!1,tension:0}}}})});</script> <h2 id="how-to-get-the-data">How to Get the Data</h2> <h3 id="option-1">Option 1</h3> <p>Download the data we used (collected in June 2021):</p> <ul> <li><code class="language-plaintext highlighter-rouge">/raw_data</code> <ul> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/raw_data/thingiverse.zip?inline=false" download=""><code>thingiverse.zip</code></a> (5.8 GB)</li> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/raw_data/myminifactory.zip?inline=false" download=""><code>myminifactory.zip</code></a> (296 KB)</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">/parsed_data</code> <ul> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/parsed_data/extracted_data.json?inline=false" download=""><code>extracted_data.json</code></a> (228 MB)<br/> The raw file information from both datasets. This is an array where each entry matches a single object in the database of either webpages. The entries are an array again that lists all file names uploaded for that entry. The single files are tuples of the file name and the upload time in UNIX format. <code class="language-plaintext highlighter-rouge">failed_opens</code> states how many source files failed to open (corrupted file). <code class="language-plaintext highlighter-rouge">nr_thingiverse_files</code> and <code class="language-plaintext highlighter-rouge">nr_myminifactory_files</code> state how many files where added from the respective database.</li> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/parsed_data/file_analysis_raw.json?inline=false" download=""><code>file_analysis_raw.json</code></a> (6.7 MB) <ul> <li><code class="language-plaintext highlighter-rouge">suffix_raw</code> all suffixes counted.</li> <li><code class="language-plaintext highlighter-rouge">suffixes_unified</code> all suffixes converted to lower case and counted.</li> <li><code class="language-plaintext highlighter-rouge">combinations_of_filetypes</code> all suffixes that contain one of the types listed in <a href="#tab:file-format-occurrences">Table 1</a> counted.</li> <li><code class="language-plaintext highlighter-rouge">object_w_type_file</code> number of objects that have an associated file with a suffix from <a href="#tab:file-format-occurrences">Table 1</a>.</li> </ul> </li> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/parsed_data/file_analysis.json?inline=false" download=""><code>file_analysis.json</code></a> (9.4 KB)<br/> Statistics about the file types in <a href="#tab:file-format-occurrences">Table 1</a>.</li> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/parsed_data/format_uploads_per_day.json?inline=false" download=""><code>format_uploads_per_day.json</code></a> (1.6 MB)<br/> Maps the upload day of an object and counts them.</li> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/parsed_data/format_uploads_per_day_per_object.json?inline=false" download=""><code>format_uploads_per_day_per_object.json</code></a> (1.5 MB)<br/> Same as <code class="language-plaintext highlighter-rouge">format_uploads_per_day</code> but uploads of the same type are ignored on the same day and object.</li> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/parsed_data/format_uploads_per_month_per_object.json?inline=false" download=""><code>format_uploads_per_month_per_object.json</code></a> (12 KB)<br/> Data from <code class="language-plaintext highlighter-rouge">format_uploads_per_day_per_object</code> but ordered so it can be used in the webpage for the graph. Data is grouped by month and their type.</li> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/parsed_data/number_of_files_per_object.json?inline=false" download=""><code>number_of_files_per_object.json</code></a> (2.8 KB)<br/> Multiple statistics about the file types from <a href="#tab:file-format-occurrences">Table 1</a>.</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">/scripts</code> <ul> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/scripts/analyze_data.py?inline=false" download=""><code>analyze_data.py</code></a> (11 KB)</li> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/scripts/extract_data.py?inline=false" download=""><code>extract_data.py</code></a> (2.3 KB)</li> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/scripts/get_data.py?inline=false" download=""><code>get_data.py</code></a> (2.6 KB)</li> <li><a href="https://git.cs.uni-paderborn.de/syssec/projects/blog-assets/-/raw/main/3d-printing-file-format-usage/scripts/plot_data.py?inline=false" download=""><code>plot_data.py</code></a> (1.5 KB)</li> </ul> </li> </ul> <h3 id="option-2">Option 2</h3> <p>Download the data yourself.</p> <p>As of June 2021 this will produce roughly 40 GB of JSON data and make about 10 million requests. The script creates a file for each available entry containing the JSON metadata. This means there will be millions of files in a single folder. I did it this way because it was the simplest, reasonably fast, method that works well with threading. This will obviously be terribly slow with a slow disk. I used an NVME SSD and had a total execution time of about 12 hours.</p> <p>If you want to do something less stupid, go ahead and change the script ;) For downloading the data once this was fine.</p> <ol> <li>Get access tokens for <code class="language-plaintext highlighter-rouge">thingiverse.com</code> and <code class="language-plaintext highlighter-rouge">myminifactory.com</code>’s APIs. <ul> <li><code class="language-plaintext highlighter-rouge">thingiverse.com</code> <ul> <li><a href="https://www.thingiverse.com/apps/create">register an app</a></li> <li>after the creation you get an token for the whole app</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">myminifactory.com</code> <ul> <li><a href="https://www.myminifactory.com/settings/developer">register an app</a></li> <li>the token shown after creation has not the required access right, you need a user-based token</li> <li>go to: <code class="language-plaintext highlighter-rouge">https://auth.myminifactory.com/web/authorize?client_id=XXX&amp;redirect_uri=YYY&amp;response_type=token&amp;state=RANDOM_STRING</code> where <code class="language-plaintext highlighter-rouge">client_id</code> should be the name of you app and <code class="language-plaintext highlighter-rouge">redirect_uri</code> the same redirect URI that was given for the registration. I used <code class="language-plaintext highlighter-rouge">ngrok</code> for the callback URI, but I’m not sure you’d actually need that.</li> <li>You will be forwarded to an URL like: <code class="language-plaintext highlighter-rouge">YYY#access_token=TTT&amp;expires_in=604800&amp;state=RANDOM_STRING&amp;token_type=Bearer</code></li> <li>The token <code class="language-plaintext highlighter-rouge">TTT</code> is the one we need.</li> </ul> </li> </ul> </li> <li>Run the <code class="language-plaintext highlighter-rouge">get_data.py</code> script with these parameters: <ul> <li>The first value is the website you want to get the data from.</li> <li>The second the access token.</li> <li>The third and fourth are the minimal and maximal ID, both sites use IDs for their objects, the API script simply tries all ID between the given values. Typically between <code class="language-plaintext highlighter-rouge">1</code> and the highest value you can find under “newest” on the respective site.</li> </ul> </li> <li>We also recommend to ZIP the data after their processing so your computer is not slowed down by the number of files. (Also the extraction script uses the ZIP files.)</li> </ol>]]></content><author><name>Jost Rossel</name></author><summary type="html"><![CDATA[an overview of the usage of different file formats used for 3D printing]]></summary></entry></feed>